nohup: ignoring input
2025-01-13 17:57:56,751 [trainer.py] => config: ldm/ldm_dddr.yaml
2025-01-13 17:57:56,751 [trainer.py] => model_name: asp
2025-01-13 17:57:56,751 [trainer.py] => backbone_type: pretrained_vit_b16_224_vpt
2025-01-13 17:57:56,751 [trainer.py] => device: ['cuda']
2025-01-13 17:57:56,751 [trainer.py] => seed: 2024
2025-01-13 17:57:56,751 [trainer.py] => dataset: cifar224
2025-01-13 17:57:56,751 [trainer.py] => init_cls: 5
2025-01-13 17:57:56,751 [trainer.py] => increment: 5
2025-01-13 17:57:56,751 [trainer.py] => kshot: 5
2025-01-13 17:57:56,751 [trainer.py] => generator_model: CIFAR_GEN
2025-01-13 17:57:56,751 [trainer.py] => z_dim: 1000
2025-01-13 17:57:56,751 [trainer.py] => conv_dim: 64
2025-01-13 17:57:56,752 [trainer.py] => img_size: 224
2025-01-13 17:57:56,752 [trainer.py] => generator_lr: 0.005
2025-01-13 17:57:56,752 [trainer.py] => pi: 100
2025-01-13 17:57:56,752 [trainer.py] => w_bn: 50.0
2025-01-13 17:57:56,752 [trainer.py] => w_noise: 0.001
2025-01-13 17:57:56,752 [trainer.py] => server_ss: 32
2025-01-13 17:57:56,752 [trainer.py] => bn_loss: 1
2025-01-13 17:57:56,752 [trainer.py] => noise: 1
2025-01-13 17:57:56,752 [trainer.py] => ie_loss: 1
2025-01-13 17:57:56,752 [trainer.py] => act_loss: 0
2025-01-13 17:57:56,752 [trainer.py] => w_ie: 1.0
2025-01-13 17:57:56,752 [trainer.py] => w_act: 0.1
2025-01-13 17:57:56,752 [trainer.py] => syn_size: 32
2025-01-13 17:57:56,752 [trainer.py] => need_syn_imgs: True
2025-01-13 17:57:56,752 [trainer.py] => ldm_ckpt: models/ldm/text2img-large/model.ckpt
2025-01-13 17:57:56,752 [trainer.py] => g_local_train_steps: 5
2025-01-13 17:57:56,752 [trainer.py] => dataset_syn: cifar100
2025-01-13 17:57:56,752 [trainer.py] => com_round_gen: 10
2025-01-13 17:57:56,752 [trainer.py] => g_sigma: 0
2025-01-13 17:57:56,752 [trainer.py] => save_cls_embeds: False
2025-01-13 17:57:56,752 [trainer.py] => syn_image_path: outputs/syn_image_60_5_pre0.0_local_bs48_5
2025-01-13 17:57:56,752 [trainer.py] => save_dir: outputs
2025-01-13 17:57:56,752 [trainer.py] => n_iter: 5
2025-01-13 17:57:56,752 [trainer.py] => num_users: 1
2025-01-13 17:57:56,752 [trainer.py] => cur_size: 5
2025-01-13 17:57:56,752 [trainer.py] => g_local_bs: 5
2025-01-13 17:57:56,752 [trainer.py] => local_bs0: 5
2025-01-13 17:57:56,752 [trainer.py] => local_bs1: 5
2025-01-13 17:57:56,752 [trainer.py] => pre_size: 48
2025-01-13 17:57:56,753 [trainer.py] => w_ce_pre: 0.5
2025-01-13 17:57:56,753 [trainer.py] => vpt_type: Deep
2025-01-13 17:57:56,753 [trainer.py] => prompt_token_num: 6
2025-01-13 17:57:56,753 [trainer.py] => avg_alpha: 0.8
2025-01-13 17:57:56,753 [trainer.py] => perturb_var: 1
2025-01-13 17:57:56,753 [trainer.py] => EMA_beta: 0.99
2025-01-13 17:57:56,753 [trainer.py] => anchor_lambda: 0.1
2025-01-13 17:57:56,753 [trainer.py] => kl_weight: 0.001
2025-01-13 17:57:56,753 [trainer.py] => TIP_init: zero
2025-01-13 17:57:56,753 [trainer.py] => tuned_epoch: 10
2025-01-13 17:57:56,753 [trainer.py] => fs_epoch: 0
2025-01-13 17:57:56,753 [trainer.py] => init_lr: 0.01
2025-01-13 17:57:56,753 [trainer.py] => fs_lr: 0.001
2025-01-13 17:57:56,753 [trainer.py] => batch_size: 48
2025-01-13 17:57:56,753 [trainer.py] => fs_batch_size: 16
2025-01-13 17:57:56,753 [trainer.py] => weight_decay: 0.0005
2025-01-13 17:57:56,753 [trainer.py] => min_lr: 0
2025-01-13 17:57:56,753 [trainer.py] => optimizer: sgd
2025-01-13 17:57:56,753 [trainer.py] => memory_size: 0
2025-01-13 17:57:56,753 [trainer.py] => memory_per_class: 0
2025-01-13 17:57:56,753 [trainer.py] => fixed_memory: False
2025-01-13 17:57:56,753 [trainer.py] => shuffle: False
2025-01-13 17:57:56,753 [trainer.py] => top_k: 5
2025-01-13 17:57:56,753 [trainer.py] => base_model_path: saved_model/asp/cifar224/5_5/asp_10_2024_pretrained_vit_b16_224_vpt.pth
2025-01-13 17:57:56,753 [trainer.py] => prefix: asp
2025-01-13 17:57:56,753 [trainer.py] => model_prefix: asp
Files already downloaded and verified
Files already downloaded and verified
2025-01-13 17:57:58,439 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
/mnt/share/yinjunhui/anaconda3/envs/cl/lib/python3.9/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore
/mnt/share/yinjunhui/anaconda3/envs/cl/lib/python3.9/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore
/mnt/share/yinjunhui/anaconda3/envs/cl/lib/python3.9/site-packages/pytorch_lightning/metrics/__init__.py:43: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5
  rank_zero_deprecation(
2025-01-13 17:57:59.629405: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-01-13 17:57:59.643999: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-01-13 17:57:59.648315: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-01-13 17:57:59.660981: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-01-13 17:58:04.292380: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
This is for the BaseNet initialization.
modelname, pretrained_vit_b16_224_vpt basicmodelname vit_base_patch16_224
Using VPT model
Using Deep Prompt
After BaseNet initialization.
2025-01-13 17:58:21,980 [trainer.py] => All params: 173596160
2025-01-13 17:58:21,981 [trainer.py] => Trainable params: 1998848
/mnt/share/yinjunhui/cl/FSCIL-Diff/ldm/models/diffusion/ddpm.py:197: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  sd = torch.load(path, map_location="cpu")
/mnt/share/yinjunhui/cl/FSCIL-Diff/models/asp.py:505: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  torch.load(self.args['ldm_ckpt'], map_location="cpu")["state_dict"],
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-13 17:58:45,296 [asp.py] => Learning on 0-5
2025-01-13 17:58:45,304 [asp.py] => training set size: 2500, fc construct set size: 2500
Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:33<02:15, 33.97s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:09<01:44, 34.92s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:46<01:11, 35.92s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:24<00:36, 36.76s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 37.40s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.65s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:38<02:35, 38.77s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:17<01:56, 38.71s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:55<01:17, 38.60s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:34<00:38, 38.51s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:12<00:00, 38.42s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:12<00:00, 38.51s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:38<02:33, 38.43s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:16<01:55, 38.39s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:54<01:16, 38.28s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:33<00:38, 38.25s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:11<00:00, 38.22s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:11<00:00, 38.26s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:38<02:33, 38.41s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:16<01:54, 38.25s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:54<01:16, 38.22s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:33<00:38, 38.25s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:11<00:00, 38.22s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:11<00:00, 38.24s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:38<02:33, 38.29s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:16<01:54, 38.26s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:54<01:16, 38.11s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:32<00:37, 38.00s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:10<00:00, 38.07s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:10<00:00, 38.10s/it]
2025-01-13 18:14:41,722 [asp.py] => total parameters: 173600001
2025-01-13 18:14:41,723 [asp.py] => trainable parameters: 2002689
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 3840
fc.sigma 1
anchor samples found
Traceback (most recent call last):
  File "/mnt/share/yinjunhui/cl/FSCIL-Diff/main.py", line 27, in <module>
    main()
  File "/mnt/share/yinjunhui/cl/FSCIL-Diff/main.py", line 13, in main
    train(args)
  File "/mnt/share/yinjunhui/cl/FSCIL-Diff/trainer.py", line 21, in train
    _train(args)
  File "/mnt/share/yinjunhui/cl/FSCIL-Diff/trainer.py", line 92, in _train
    model.incremental_train(teacher, generator, data_manager)
  File "/mnt/share/yinjunhui/cl/FSCIL-Diff/models/asp.py", line 166, in incremental_train
    self._train(classes_learned, teacher, self.train_loader, self.test_loader, self.train_loader_for_protonet, self.local_cur_loaders)
  File "/mnt/share/yinjunhui/cl/FSCIL-Diff/models/asp.py", line 209, in _train
    self._init_train(local_cur_loaders[0], test_loader, optimizer, scheduler)
  File "/mnt/share/yinjunhui/cl/FSCIL-Diff/models/asp.py", line 273, in _init_train
    inputs = torch.cat([inputs, anchor_samples[c].unsqueeze(0).to(self._device)])
IndexError: list index out of range
Class Inversion:   0%|          | 0/10 [16:14<?, ?it/s]
