nohup: ignoring input
2025-01-10 23:31:20,007 [trainer.py] => config: ldm/ldm_dddr.yaml
2025-01-10 23:31:20,007 [trainer.py] => model_name: asp
2025-01-10 23:31:20,007 [trainer.py] => backbone_type: pretrained_vit_b16_224_vpt
2025-01-10 23:31:20,007 [trainer.py] => device: ['cuda']
2025-01-10 23:31:20,007 [trainer.py] => seed: 2024
2025-01-10 23:31:20,007 [trainer.py] => dataset: cifar224
2025-01-10 23:31:20,007 [trainer.py] => init_cls: 5
2025-01-10 23:31:20,007 [trainer.py] => increment: 5
2025-01-10 23:31:20,007 [trainer.py] => kshot: 5
2025-01-10 23:31:20,007 [trainer.py] => generator_model: CIFAR_GEN
2025-01-10 23:31:20,008 [trainer.py] => z_dim: 1000
2025-01-10 23:31:20,008 [trainer.py] => conv_dim: 64
2025-01-10 23:31:20,008 [trainer.py] => img_size: 224
2025-01-10 23:31:20,008 [trainer.py] => generator_lr: 0.005
2025-01-10 23:31:20,008 [trainer.py] => pi: 100
2025-01-10 23:31:20,008 [trainer.py] => w_bn: 50.0
2025-01-10 23:31:20,008 [trainer.py] => w_noise: 0.001
2025-01-10 23:31:20,008 [trainer.py] => server_ss: 32
2025-01-10 23:31:20,008 [trainer.py] => bn_loss: 1
2025-01-10 23:31:20,008 [trainer.py] => noise: 1
2025-01-10 23:31:20,008 [trainer.py] => ie_loss: 1
2025-01-10 23:31:20,008 [trainer.py] => act_loss: 0
2025-01-10 23:31:20,008 [trainer.py] => w_ie: 1.0
2025-01-10 23:31:20,008 [trainer.py] => w_act: 0.1
2025-01-10 23:31:20,008 [trainer.py] => syn_size: 32
2025-01-10 23:31:20,008 [trainer.py] => need_syn_imgs: True
2025-01-10 23:31:20,008 [trainer.py] => g_local_bs: 5
2025-01-10 23:31:20,008 [trainer.py] => ldm_ckpt: models/ldm/text2img-large/model.ckpt
2025-01-10 23:31:20,008 [trainer.py] => g_local_train_steps: 5
2025-01-10 23:31:20,008 [trainer.py] => dataset_syn: cifar100
2025-01-10 23:31:20,008 [trainer.py] => com_round_gen: 10
2025-01-10 23:31:20,008 [trainer.py] => g_sigma: 0
2025-01-10 23:31:20,008 [trainer.py] => save_cls_embeds: False
2025-01-10 23:31:20,008 [trainer.py] => syn_image_path: outputs/syn_image_5_5_pre0.5_local_bs5
2025-01-10 23:31:20,008 [trainer.py] => save_dir: outputs
2025-01-10 23:31:20,008 [trainer.py] => n_iter: 5
2025-01-10 23:31:20,008 [trainer.py] => num_users: 1
2025-01-10 23:31:20,008 [trainer.py] => cur_size: 50
2025-01-10 23:31:20,008 [trainer.py] => local_bs: 5
2025-01-10 23:31:20,008 [trainer.py] => pre_size: 48
2025-01-10 23:31:20,008 [trainer.py] => w_ce_pre: 0.5
2025-01-10 23:31:20,008 [trainer.py] => vpt_type: Deep
2025-01-10 23:31:20,009 [trainer.py] => prompt_token_num: 6
2025-01-10 23:31:20,009 [trainer.py] => avg_alpha: 0.8
2025-01-10 23:31:20,009 [trainer.py] => perturb_var: 1
2025-01-10 23:31:20,009 [trainer.py] => EMA_beta: 0.99
2025-01-10 23:31:20,009 [trainer.py] => anchor_lambda: 0.1
2025-01-10 23:31:20,009 [trainer.py] => kl_weight: 0.001
2025-01-10 23:31:20,009 [trainer.py] => TIP_init: zero
2025-01-10 23:31:20,009 [trainer.py] => tuned_epoch: 10
2025-01-10 23:31:20,009 [trainer.py] => fs_epoch: 0
2025-01-10 23:31:20,009 [trainer.py] => init_lr: 0.01
2025-01-10 23:31:20,009 [trainer.py] => fs_lr: 0.001
2025-01-10 23:31:20,009 [trainer.py] => batch_size: 48
2025-01-10 23:31:20,009 [trainer.py] => fs_batch_size: 16
2025-01-10 23:31:20,009 [trainer.py] => weight_decay: 0.0005
2025-01-10 23:31:20,009 [trainer.py] => min_lr: 0
2025-01-10 23:31:20,009 [trainer.py] => optimizer: sgd
2025-01-10 23:31:20,009 [trainer.py] => memory_size: 0
2025-01-10 23:31:20,009 [trainer.py] => memory_per_class: 0
2025-01-10 23:31:20,009 [trainer.py] => fixed_memory: False
2025-01-10 23:31:20,009 [trainer.py] => shuffle: False
2025-01-10 23:31:20,009 [trainer.py] => top_k: 5
2025-01-10 23:31:20,009 [trainer.py] => base_model_path: saved_model/asp/cifar224/5_5/asp_10_2024_pretrained_vit_b16_224_vpt.pth
2025-01-10 23:31:20,009 [trainer.py] => prefix: asp
2025-01-10 23:31:20,009 [trainer.py] => model_prefix: asp
Files already downloaded and verified
Files already downloaded and verified
2025-01-10 23:31:21,607 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
/mnt/share/yinjunhui/anaconda3/envs/cl/lib/python3.9/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore
/mnt/share/yinjunhui/anaconda3/envs/cl/lib/python3.9/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore
/mnt/share/yinjunhui/anaconda3/envs/cl/lib/python3.9/site-packages/pytorch_lightning/metrics/__init__.py:43: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5
  rank_zero_deprecation(
2025-01-10 23:31:22.988917: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-01-10 23:31:23.002453: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-01-10 23:31:23.006558: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-01-10 23:31:23.018435: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-01-10 23:31:23.802274: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
This is for the BaseNet initialization.
modelname, pretrained_vit_b16_224_vpt basicmodelname vit_base_patch16_224
Using VPT model
Using Deep Prompt
After BaseNet initialization.
2025-01-10 23:31:30,387 [trainer.py] => All params: 173596160
2025-01-10 23:31:30,388 [trainer.py] => Trainable params: 1998848
/mnt/share/yinjunhui/cl/FSCIL-Diff/ldm/models/diffusion/ddpm.py:197: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  sd = torch.load(path, map_location="cpu")
/mnt/share/yinjunhui/cl/FSCIL-Diff/models/asp.py:505: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  torch.load(self.args['ldm_ckpt'], map_location="cpu")["state_dict"],
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-10 23:31:46,657 [asp.py] => Learning on 0-5
2025-01-10 23:31:46,663 [asp.py] => training set size: 2500, fc construct set size: 2500
Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:34<02:16, 34.06s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:08<01:43, 34.53s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:44<01:10, 35.20s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:21<00:35, 35.81s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:58<00:00, 36.31s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:58<00:00, 35.77s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.36s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.30s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.26s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.24s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.25s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.26s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.42s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.35s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.28s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.24s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.23s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.26s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.36s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.27s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.40s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.23s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.23s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.26s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.45s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.32s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.34s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.33s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.32s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.33s/it]
2025-01-10 23:47:14,890 [asp.py] => total parameters: 173600001
2025-01-10 23:47:14,891 [asp.py] => trainable parameters: 2002689
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 3840
fc.sigma 1
anchor samples found
2025-01-10 23:48:19,160 [asp.py] => Task 0, Epoch 1 => Loss 1.596, Train_accy 60.73, Test_curr_accy 98.00, Test_accy 98.00
anchor samples found
2025-01-10 23:49:23,086 [asp.py] => Task 0, Epoch 2 => Loss 0.671, Train_accy 89.38, Test_curr_accy 98.60, Test_accy 98.60
anchor samples found
2025-01-10 23:50:26,820 [asp.py] => Task 0, Epoch 3 => Loss 0.526, Train_accy 91.85, Test_curr_accy 97.60, Test_accy 97.60
anchor samples found
2025-01-10 23:51:30,484 [asp.py] => Task 0, Epoch 4 => Loss 0.553, Train_accy 91.71, Test_curr_accy 98.60, Test_accy 98.60
anchor samples found
2025-01-10 23:52:33,919 [asp.py] => Task 0, Epoch 5 => Loss 0.442, Train_accy 92.80, Test_curr_accy 98.00, Test_accy 98.00
anchor samples found
2025-01-10 23:53:38,116 [asp.py] => Task 0, Epoch 6 => Loss 0.339, Train_accy 93.35, Test_curr_accy 98.60, Test_accy 98.60
anchor samples found
2025-01-10 23:54:41,794 [asp.py] => Task 0, Epoch 7 => Loss 0.296, Train_accy 94.47, Test_curr_accy 95.40, Test_accy 95.40
anchor samples found
2025-01-10 23:55:45,396 [asp.py] => Task 0, Epoch 8 => Loss 0.274, Train_accy 94.55, Test_curr_accy 97.40, Test_accy 97.40
anchor samples found
2025-01-10 23:56:48,996 [asp.py] => Task 0, Epoch 9 => Loss 0.241, Train_accy 94.69, Test_curr_accy 97.00, Test_accy 97.00
anchor samples found
2025-01-10 23:57:52,444 [asp.py] => Task 0, Epoch 10 => Loss 0.244, Train_accy 95.02, Test_curr_accy 95.00, Test_accy 95.00
2025-01-10 23:58:20,540 [trainer.py] => Top1 curve: [97.8]
2025-01-10 23:58:20,541 [trainer.py] => Average Accuracy (Top1): 97.8   (Harmonic Accuracy): None (Old Acc): 97.8 (New Acc): [] 

2025-01-10 23:58:20,541 [trainer.py] => All params: 173600001
2025-01-10 23:58:20,542 [trainer.py] => Trainable params: 2002689
Class Inversion:   0%|          | 0/10 [26:39<?, ?it/s]
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-10 23:58:46,473 [asp.py] => Learning on 5-10
2025-01-10 23:58:46,493 [asp.py] => training set size: 25, fc construct set size: 25
Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:35<02:22, 35.51s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:11<01:48, 36.02s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:48<01:12, 36.40s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:25<00:36, 36.71s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.93s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.65s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.36s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.34s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.32s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.35s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.37s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.35s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.42s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.32s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.27s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.25s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.26s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.28s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.46s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.37s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.37s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.33s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.36s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.36s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.46s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.39s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.36s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.33s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.34s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.35s/it]
2025-01-11 00:14:21,936 [asp.py] => total parameters: 173603841
2025-01-11 00:14:21,937 [asp.py] => trainable parameters: 2006529
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 7680
fc.sigma 1
2025-01-11 00:14:28,629 [trainer.py] => Top1 curve: [97.8, 95.8]
2025-01-11 00:14:28,629 [trainer.py] => Average Accuracy (Top1): 96.8   (Harmonic Accuracy): 95.76617954070981 (Old Acc): 97.6 (New Acc): 94.0 

2025-01-11 00:14:28,630 [trainer.py] => All params: 173603841
2025-01-11 00:14:28,631 [trainer.py] => Trainable params: 2006529
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-11 00:14:47,501 [asp.py] => Learning on 10-15
2025-01-11 00:14:47,509 [asp.py] => training set size: 25, fc construct set size: 25

Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s][A

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:35<02:23, 35.87s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:12<01:48, 36.14s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:49<01:13, 36.53s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:26<00:36, 36.80s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 37.00s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.75s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.50s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.36s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.32s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.41s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.36s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.37s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.46s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.36s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.33s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.30s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.28s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.31s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.42s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.36s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.34s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.32s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.29s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.31s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:38<02:33, 38.48s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:15<01:52, 37.56s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.42s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.36s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.34s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.45s/it]
2025-01-11 00:30:24,122 [asp.py] => total parameters: 173607681
2025-01-11 00:30:24,123 [asp.py] => trainable parameters: 2010369
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 11520
fc.sigma 1
2025-01-11 00:30:33,318 [trainer.py] => Top1 curve: [97.8, 95.8, 86.47]
2025-01-11 00:30:33,318 [trainer.py] => Average Accuracy (Top1): 93.35666666666667   (Harmonic Accuracy): 88.30056242969628 (Old Acc): 96.2 (New Acc): 81.6 

2025-01-11 00:30:33,319 [trainer.py] => All params: 173607681
2025-01-11 00:30:33,320 [trainer.py] => Trainable params: 2010369
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-11 00:30:52,848 [asp.py] => Learning on 15-20
2025-01-11 00:30:52,858 [asp.py] => training set size: 25, fc construct set size: 25


Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s][A[AClass Inversion:   0%|          | 0/10 [32:05<?, ?it/s]
Class Inversion:   0%|          | 0/10 [16:05<?, ?it/s]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s]Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:35<02:23, 35.87s/it]Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:12<01:48, 36.26s/it]Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:49<01:13, 36.61s/it]Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:26<00:36, 36.83s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.95s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.75s/it]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s]Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.55s/it]Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:15<01:52, 37.50s/it]Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.41s/it]Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.42s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.36s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.40s/it]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s]Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.51s/it]Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.42s/it]Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.37s/it]Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.40s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.37s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.39s/it]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s]Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.40s/it]Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.38s/it]Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.34s/it]Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.22s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.13s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.21s/it]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s]Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.39s/it]Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.32s/it]Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.29s/it]Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.30s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.32s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.32s/it]
2025-01-11 00:46:28,913 [asp.py] => total parameters: 173611521
2025-01-11 00:46:28,914 [asp.py] => trainable parameters: 2014209
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 15360
fc.sigma 1
2025-01-11 00:46:39,810 [trainer.py] => Top1 curve: [97.8, 95.8, 86.47, 84.0]
2025-01-11 00:46:39,810 [trainer.py] => Average Accuracy (Top1): 91.0175   (Harmonic Accuracy): 87.27272727272727 (Old Acc): 96.0 (New Acc): 80.0 

2025-01-11 00:46:39,811 [trainer.py] => All params: 173611521
2025-01-11 00:46:39,811 [trainer.py] => Trainable params: 2014209
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-11 00:46:58,906 [asp.py] => Learning on 20-25
2025-01-11 00:46:58,917 [asp.py] => training set size: 25, fc construct set size: 25
Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:35<02:23, 35.94s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:12<01:48, 36.21s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:49<01:13, 36.58s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:26<00:36, 36.79s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.94s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.74s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.40s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.14s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.28s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.33s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.36s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.32s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.56s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.45s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.39s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.35s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.32s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.36s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.47s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.41s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.37s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.36s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.34s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.36s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.40s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.18s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.26s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.25s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.26s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.26s/it]
2025-01-11 01:02:34,726 [asp.py] => total parameters: 173615361
2025-01-11 01:02:34,727 [asp.py] => trainable parameters: 2018049
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 19200
fc.sigma 1
2025-01-11 01:02:48,175 [trainer.py] => Top1 curve: [97.8, 95.8, 86.47, 84.0, 83.04]
2025-01-11 01:02:48,176 [trainer.py] => Average Accuracy (Top1): 89.422   (Harmonic Accuracy): 86.99435414884516 (Old Acc): 95.4 (New Acc): 79.95 

2025-01-11 01:02:48,177 [trainer.py] => All params: 173615361
2025-01-11 01:02:48,177 [trainer.py] => Trainable params: 2018049
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-11 01:03:07,768 [asp.py] => Learning on 25-30
2025-01-11 01:03:07,780 [asp.py] => training set size: 25, fc construct set size: 25

Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s][A


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:35<02:23, 35.82s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:12<01:48, 36.26s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:49<01:13, 36.59s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:26<00:36, 36.79s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.93s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.73s/it]



Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.38s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.29s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.32s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.33s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.37s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.35s/it]



Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.61s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:15<01:52, 37.48s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.41s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.35s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.34s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.38s/it]



Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.52s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.43s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.42s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.40s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.39s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.41s/it]



Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.48s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.40s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.37s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.35s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.33s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.36s/it]
2025-01-11 01:18:44,730 [asp.py] => total parameters: 173619201
2025-01-11 01:18:44,731 [asp.py] => trainable parameters: 2021889
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 23040
fc.sigma 1
2025-01-11 01:19:00,176 [trainer.py] => Top1 curve: [97.8, 95.8, 86.47, 84.0, 83.04, 79.1]
2025-01-11 01:19:00,177 [trainer.py] => Average Accuracy (Top1): 87.70166666666667   (Harmonic Accuracy): 84.44909983633389 (Old Acc): 95.2 (New Acc): 75.88000000000001 

2025-01-11 01:19:00,178 [trainer.py] => All params: 173619201
2025-01-11 01:19:00,178 [trainer.py] => Trainable params: 2021889
Class Inversion:   0%|          | 0/10 [48:19<?, ?it/s]
Class Inversion:   0%|          | 0/10 [32:13<?, ?it/s]
Class Inversion:   0%|          | 0/10 [16:04<?, ?it/s]
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-11 01:19:19,568 [asp.py] => Learning on 30-35
2025-01-11 01:19:19,582 [asp.py] => training set size: 25, fc construct set size: 25
Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:35<02:23, 35.89s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:12<01:48, 36.31s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:49<01:13, 36.58s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:26<00:36, 36.78s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.91s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.73s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.43s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.39s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.35s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.32s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.31s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.33s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.56s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.46s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.42s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.40s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.39s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.41s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:28, 37.12s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.20s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.22s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:28<00:37, 37.25s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.24s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.23s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.43s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.32s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.33s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.29s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.26s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.29s/it]
2025-01-11 01:34:55,673 [asp.py] => total parameters: 173623041
2025-01-11 01:34:55,674 [asp.py] => trainable parameters: 2025729
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 26880
fc.sigma 1
2025-01-11 01:35:13,849 [trainer.py] => Top1 curve: [97.8, 95.8, 86.47, 84.0, 83.04, 79.1, 76.03]
2025-01-11 01:35:13,850 [trainer.py] => Average Accuracy (Top1): 86.03428571428572   (Harmonic Accuracy): 82.42003577817532 (Old Acc): 94.8 (New Acc): 72.9 

2025-01-11 01:35:13,851 [trainer.py] => All params: 173623041
2025-01-11 01:35:13,851 [trainer.py] => Trainable params: 2025729
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-11 01:35:33,583 [asp.py] => Learning on 35-40
2025-01-11 01:35:33,597 [asp.py] => training set size: 25, fc construct set size: 25

Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s][A

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:35<02:23, 35.82s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:12<01:48, 36.25s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:49<01:13, 36.58s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:26<00:36, 36.77s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.90s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.71s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.41s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.34s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.33s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.33s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.30s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.32s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.48s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.40s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.37s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.38s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.39s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.39s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.55s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.45s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.41s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.39s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.36s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.39s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.48s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.37s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.19s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.24s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.28s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.28s/it]
2025-01-11 01:51:10,366 [asp.py] => total parameters: 173626881
2025-01-11 01:51:10,367 [asp.py] => trainable parameters: 2029569
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 30720
fc.sigma 1
2025-01-11 01:51:30,588 [trainer.py] => Top1 curve: [97.8, 95.8, 86.47, 84.0, 83.04, 79.1, 76.03, 73.4]
2025-01-11 01:51:30,589 [trainer.py] => Average Accuracy (Top1): 84.455   (Harmonic Accuracy): 79.98314606741575 (Old Acc): 92.0 (New Acc): 70.74285714285715 

2025-01-11 01:51:30,590 [trainer.py] => All params: 173626881
2025-01-11 01:51:30,590 [trainer.py] => Trainable params: 2029569
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-11 01:51:49,680 [asp.py] => Learning on 40-45
2025-01-11 01:51:49,700 [asp.py] => training set size: 25, fc construct set size: 25


Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s][A[A


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:35<02:23, 35.85s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:12<01:48, 36.13s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:49<01:12, 36.49s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:26<00:36, 36.72s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.91s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.68s/it]



Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.35s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.32s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.31s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.32s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.31s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.32s/it]



Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.47s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.41s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.40s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.39s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.39s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.40s/it]



Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.53s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.45s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.40s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.36s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.34s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.38s/it]



Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.48s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.40s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.36s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.35s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.35s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.36s/it]
2025-01-11 02:07:26,412 [asp.py] => total parameters: 173630721
2025-01-11 02:07:26,414 [asp.py] => trainable parameters: 2033409
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 34560
fc.sigma 1
2025-01-11 02:07:48,595 [trainer.py] => Top1 curve: [97.8, 95.8, 86.47, 84.0, 83.04, 79.1, 76.03, 73.4, 73.04]
2025-01-11 02:07:48,595 [trainer.py] => Average Accuracy (Top1): 83.18666666666667   (Harmonic Accuracy): 79.88012307692308 (Old Acc): 91.8 (New Acc): 70.7 

2025-01-11 02:07:48,596 [trainer.py] => All params: 173630721
2025-01-11 02:07:48,597 [trainer.py] => Trainable params: 2033409
Class Inversion:   0%|          | 0/10 [48:34<?, ?it/s]
Class Inversion:   0%|          | 0/10 [32:20<?, ?it/s]
Class Inversion:   0%|          | 0/10 [16:04<?, ?it/s]
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-11 02:08:08,441 [asp.py] => Learning on 45-50
2025-01-11 02:08:08,457 [asp.py] => training set size: 25, fc construct set size: 25
Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:35<02:23, 35.83s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:12<01:48, 36.28s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:49<01:13, 36.62s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:26<00:36, 36.82s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.98s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.77s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.41s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.38s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.32s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.30s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.30s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.32s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.39s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.27s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.28s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.24s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.26s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.27s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.45s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.37s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.32s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.33s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.31s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.33s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.42s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.28s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.29s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.26s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.27s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.28s/it]
2025-01-11 02:23:47,796 [asp.py] => total parameters: 173634561
2025-01-11 02:23:47,796 [asp.py] => trainable parameters: 2037249
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 38400
fc.sigma 1
2025-01-11 02:24:12,245 [trainer.py] => Top1 curve: [97.8, 95.8, 86.47, 84.0, 83.04, 79.1, 76.03, 73.4, 73.04, 71.3]
2025-01-11 02:24:12,245 [trainer.py] => Average Accuracy (Top1): 81.99799999999999   (Harmonic Accuracy): 78.7980654967528 (Old Acc): 91.8 (New Acc): 69.02222222222221 

2025-01-11 02:24:12,246 [trainer.py] => All params: 173634561
2025-01-11 02:24:12,247 [trainer.py] => Trainable params: 2037249
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-11 02:24:30,755 [asp.py] => Learning on 50-55
2025-01-11 02:24:30,774 [asp.py] => training set size: 25, fc construct set size: 25

Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s][A

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:35<02:23, 35.80s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:12<01:48, 36.19s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:49<01:13, 36.55s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:26<00:36, 36.72s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.88s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.68s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.34s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.23s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.22s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:28<00:37, 37.21s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.20s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.22s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.39s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.33s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.30s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:28<00:37, 37.16s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.17s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.21s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.37s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.34s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.36s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.36s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.37s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.36s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.52s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.36s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.33s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.33s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.35s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.36s/it]
2025-01-11 02:40:06,591 [asp.py] => total parameters: 173638401
2025-01-11 02:40:06,592 [asp.py] => trainable parameters: 2041089
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 42240
fc.sigma 1
2025-01-11 02:40:33,417 [trainer.py] => Top1 curve: [97.8, 95.8, 86.47, 84.0, 83.04, 79.1, 76.03, 73.4, 73.04, 71.3, 71.71]
2025-01-11 02:40:33,418 [trainer.py] => Average Accuracy (Top1): 81.06272727272727   (Harmonic Accuracy): 79.2378947368421 (Old Acc): 91.8 (New Acc): 69.69999999999999 

2025-01-11 02:40:33,419 [trainer.py] => All params: 173638401
2025-01-11 02:40:33,419 [trainer.py] => Trainable params: 2041089
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-11 02:40:52,080 [asp.py] => Learning on 55-60
2025-01-11 02:40:52,100 [asp.py] => training set size: 25, fc construct set size: 25


Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s][A[AClass Inversion:   0%|          | 0/10 [32:43<?, ?it/s]
Class Inversion:   0%|          | 0/10 [16:21<?, ?it/s]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s]Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:35<02:23, 35.95s/it]Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:12<01:49, 36.40s/it]Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:49<01:13, 36.70s/it]Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:26<00:36, 36.92s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:04<00:00, 37.05s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:04<00:00, 36.85s/it]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s]Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.43s/it]Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.33s/it]Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.30s/it]Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.28s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.32s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.32s/it]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s]Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.48s/it]Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.42s/it]Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.41s/it]Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.37s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.34s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.37s/it]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s]Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.38s/it]Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.35s/it]Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.39s/it]Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.36s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.38s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.38s/it]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s]Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.58s/it]Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:15<01:52, 37.49s/it]Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.45s/it]Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.41s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.38s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.42s/it]
2025-01-11 02:56:31,121 [asp.py] => total parameters: 173642241
2025-01-11 02:56:31,122 [asp.py] => trainable parameters: 2044929
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 46080
fc.sigma 1
2025-01-11 02:57:00,284 [trainer.py] => Top1 curve: [97.8, 95.8, 86.47, 84.0, 83.04, 79.1, 76.03, 73.4, 73.04, 71.3, 71.71, 69.72]
2025-01-11 02:57:00,284 [trainer.py] => Average Accuracy (Top1): 80.11749999999999   (Harmonic Accuracy): 77.87515690973412 (Old Acc): 91.6 (New Acc): 67.72727272727273 

2025-01-11 02:57:00,285 [trainer.py] => All params: 173642241
2025-01-11 02:57:00,285 [trainer.py] => Trainable params: 2044929
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-11 02:57:19,996 [asp.py] => Learning on 60-65
2025-01-11 02:57:20,024 [asp.py] => training set size: 25, fc construct set size: 25
Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:35<02:23, 35.89s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:12<01:49, 36.35s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:49<01:13, 36.64s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:26<00:36, 36.86s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:04<00:00, 37.01s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:04<00:00, 36.81s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.42s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.32s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.32s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.31s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.31s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.32s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.44s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.36s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.32s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.30s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.29s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.31s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.43s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.32s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.33s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.30s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.31s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.32s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.66s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:15<01:52, 37.52s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:15, 37.51s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:30<00:37, 37.51s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.48s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.50s/it]
2025-01-11 03:12:58,550 [asp.py] => total parameters: 173646081
2025-01-11 03:12:58,551 [asp.py] => trainable parameters: 2048769
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 49920
fc.sigma 1
2025-01-11 03:13:29,954 [trainer.py] => Top1 curve: [97.8, 95.8, 86.47, 84.0, 83.04, 79.1, 76.03, 73.4, 73.04, 71.3, 71.71, 69.72, 68.49]
2025-01-11 03:13:29,954 [trainer.py] => Average Accuracy (Top1): 79.22307692307692   (Harmonic Accuracy): 77.04251503323137 (Old Acc): 91.4 (New Acc): 66.58333333333334 

2025-01-11 03:13:29,955 [trainer.py] => All params: 173646081
2025-01-11 03:13:29,956 [trainer.py] => Trainable params: 2048769
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-11 03:13:48,717 [asp.py] => Learning on 65-70
2025-01-11 03:13:48,735 [asp.py] => training set size: 25, fc construct set size: 25

Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s][A


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:35<02:23, 35.97s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:12<01:49, 36.37s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:49<01:13, 36.66s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:26<00:36, 36.87s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:04<00:00, 37.01s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:04<00:00, 36.82s/it]



Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.42s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.32s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.31s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.30s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.30s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.31s/it]



Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.40s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.33s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.32s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.32s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.31s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.32s/it]



Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.46s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.36s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.32s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.31s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.31s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.33s/it]



Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.38s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.36s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.33s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.35s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.36s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.36s/it]
2025-01-11 03:29:26,707 [asp.py] => total parameters: 173649921
2025-01-11 03:29:26,708 [asp.py] => trainable parameters: 2052609
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 53760
fc.sigma 1
2025-01-11 03:30:00,719 [trainer.py] => Top1 curve: [97.8, 95.8, 86.47, 84.0, 83.04, 79.1, 76.03, 73.4, 73.04, 71.3, 71.71, 69.72, 68.49, 67.84]
2025-01-11 03:30:00,720 [trainer.py] => Average Accuracy (Top1): 78.40999999999998   (Harmonic Accuracy): 76.73120546608101 (Old Acc): 91.6 (New Acc): 66.01538461538462 

2025-01-11 03:30:00,721 [trainer.py] => All params: 173649921
2025-01-11 03:30:00,721 [trainer.py] => Trainable params: 2052609
Class Inversion:   0%|          | 0/10 [49:14<?, ?it/s]
Class Inversion:   0%|          | 0/10 [32:46<?, ?it/s]
Class Inversion:   0%|          | 0/10 [16:17<?, ?it/s]
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-11 03:30:36,569 [asp.py] => Learning on 70-75
2025-01-11 03:30:36,597 [asp.py] => training set size: 25, fc construct set size: 25
Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:35<02:21, 35.38s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:11<01:47, 35.94s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:48<01:12, 36.36s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:25<00:36, 36.62s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:02<00:00, 36.80s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:02<00:00, 36.54s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.32s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.26s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.28s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.27s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.28s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.28s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.44s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.35s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.33s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.31s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.30s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.32s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.53s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.43s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.44s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.43s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.41s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.43s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.48s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.38s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.36s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.39s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.39s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.39s/it]
2025-01-11 03:46:15,230 [asp.py] => total parameters: 173653761
2025-01-11 03:46:15,231 [asp.py] => trainable parameters: 2056449
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 57600
fc.sigma 1
2025-01-11 03:46:51,927 [trainer.py] => Top1 curve: [97.8, 95.8, 86.47, 84.0, 83.04, 79.1, 76.03, 73.4, 73.04, 71.3, 71.71, 69.72, 68.49, 67.84, 65.64]
2025-01-11 03:46:51,927 [trainer.py] => Average Accuracy (Top1): 77.55866666666665   (Harmonic Accuracy): 75.03007935043365 (Old Acc): 91.0 (New Acc): 63.82857142857142 

2025-01-11 03:46:51,928 [trainer.py] => All params: 173653761
2025-01-11 03:46:51,929 [trainer.py] => Trainable params: 2056449
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-11 03:47:13,510 [asp.py] => Learning on 75-80
2025-01-11 03:47:13,551 [asp.py] => training set size: 25, fc construct set size: 25

Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s][A

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:35<02:23, 35.90s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:12<01:48, 36.18s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:49<01:13, 36.54s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:26<00:36, 36.76s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.91s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:03<00:00, 36.70s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.42s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.34s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.32s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.30s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.31s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.32s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.54s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.44s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.39s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.40s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.37s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.40s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.51s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.38s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.32s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.29s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.28s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.31s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.46s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.41s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.38s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.36s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.37s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.38s/it]
2025-01-11 04:02:52,139 [asp.py] => total parameters: 173657601
2025-01-11 04:02:52,140 [asp.py] => trainable parameters: 2060289
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 61440
fc.sigma 1
2025-01-11 04:03:30,803 [trainer.py] => Top1 curve: [97.8, 95.8, 86.47, 84.0, 83.04, 79.1, 76.03, 73.4, 73.04, 71.3, 71.71, 69.72, 68.49, 67.84, 65.64, 66.35]
2025-01-11 04:03:30,803 [trainer.py] => Average Accuracy (Top1): 76.85812499999999   (Harmonic Accuracy): 75.69319192610332 (Old Acc): 91.2 (New Acc): 64.69333333333334 

2025-01-11 04:03:30,804 [trainer.py] => All params: 173657601
2025-01-11 04:03:30,805 [trainer.py] => Trainable params: 2060289
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-11 04:03:50,203 [asp.py] => Learning on 80-85
2025-01-11 04:03:50,230 [asp.py] => training set size: 25, fc construct set size: 25


Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s][A[A


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:36<02:24, 36.06s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:12<01:49, 36.46s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:49<01:13, 36.77s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:27<00:36, 36.97s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:04<00:00, 37.08s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:04<00:00, 36.90s/it]



Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.55s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.41s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.39s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.40s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.39s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.40s/it]



Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.47s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.42s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.41s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.40s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.39s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.40s/it]



Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.46s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.38s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.36s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.33s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.31s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.34s/it]



Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A[A


Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.57s/it][A[A[A


Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.45s/it][A[A[A


Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.40s/it][A[A[A


Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.39s/it][A[A[A


Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.36s/it][A[A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.39s/it]
2025-01-11 04:19:30,218 [asp.py] => total parameters: 173661441
2025-01-11 04:19:30,219 [asp.py] => trainable parameters: 2064129
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 65280
fc.sigma 1
2025-01-11 04:20:10,852 [trainer.py] => Top1 curve: [97.8, 95.8, 86.47, 84.0, 83.04, 79.1, 76.03, 73.4, 73.04, 71.3, 71.71, 69.72, 68.49, 67.84, 65.64, 66.35, 66.48]
2025-01-11 04:20:10,852 [trainer.py] => Average Accuracy (Top1): 76.24764705882352   (Harmonic Accuracy): 75.86005924265471 (Old Acc): 91.2 (New Acc): 64.9375 

2025-01-11 04:20:10,853 [trainer.py] => All params: 173661441
2025-01-11 04:20:10,854 [trainer.py] => Trainable params: 2064129
Class Inversion:   0%|          | 0/10 [49:38<?, ?it/s]
Class Inversion:   0%|          | 0/10 [33:02<?, ?it/s]
Class Inversion:   0%|          | 0/10 [16:25<?, ?it/s]
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-11 04:20:31,249 [asp.py] => Learning on 85-90
2025-01-11 04:20:31,275 [asp.py] => training set size: 25, fc construct set size: 25
Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:35<02:23, 35.93s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:12<01:49, 36.43s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:49<01:13, 36.77s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:27<00:37, 37.01s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:04<00:00, 37.15s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:04<00:00, 36.93s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.49s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.40s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.37s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.36s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.33s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.36s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.42s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.35s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.34s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.35s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.34s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.35s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.52s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.39s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.42s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.41s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:09<00:00, 38.25s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:09<00:00, 37.88s/it]

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A
Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:28, 37.04s/it][A
Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:51, 37.20s/it][A
Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:51<01:14, 37.26s/it][A
Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.31s/it][A
Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.31s/it][ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.27s/it]
2025-01-11 04:36:12,958 [asp.py] => total parameters: 173665281
2025-01-11 04:36:12,959 [asp.py] => trainable parameters: 2067969
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 69120
fc.sigma 1
2025-01-11 04:36:55,688 [trainer.py] => Top1 curve: [97.8, 95.8, 86.47, 84.0, 83.04, 79.1, 76.03, 73.4, 73.04, 71.3, 71.71, 69.72, 68.49, 67.84, 65.64, 66.35, 66.48, 66.61]
2025-01-11 04:36:55,689 [trainer.py] => Average Accuracy (Top1): 75.71222222222221   (Harmonic Accuracy): 75.95329566854991 (Old Acc): 91.0 (New Acc): 65.1764705882353 

2025-01-11 04:36:55,690 [trainer.py] => All params: 173665281
2025-01-11 04:36:55,691 [trainer.py] => Trainable params: 2067969
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-11 04:37:15,645 [asp.py] => Learning on 90-95
2025-01-11 04:37:15,667 [asp.py] => training set size: 25, fc construct set size: 25

Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s][A

Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:35<02:23, 35.89s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:12<01:49, 36.38s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:49<01:13, 36.72s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:26<00:36, 36.92s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:04<00:00, 37.07s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:04<00:00, 36.86s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.55s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:15<01:52, 37.54s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:15, 37.51s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.48s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.46s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.48s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:39<02:39, 40.00s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:16<01:54, 38.18s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:54<01:15, 37.77s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:31<00:37, 37.62s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:08<00:00, 37.53s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:08<00:00, 37.79s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.56s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:15<01:52, 37.49s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.45s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.47s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.45s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.46s/it]


Sampling:   0%|          | 0/5 [00:00<?, ?it/s][A[A

Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.46s/it][A[A

Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.38s/it][A[A

Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.32s/it][A[A

Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.29s/it][A[A

Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.28s/it][A[ASampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.31s/it]
2025-01-11 04:53:02,808 [asp.py] => total parameters: 173669121
2025-01-11 04:53:02,809 [asp.py] => trainable parameters: 2071809
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 72960
fc.sigma 1
2025-01-11 04:53:47,408 [trainer.py] => Top1 curve: [97.8, 95.8, 86.47, 84.0, 83.04, 79.1, 76.03, 73.4, 73.04, 71.3, 71.71, 69.72, 68.49, 67.84, 65.64, 66.35, 66.48, 66.61, 65.79]
2025-01-11 04:53:47,408 [trainer.py] => Average Accuracy (Top1): 75.18999999999998   (Harmonic Accuracy): 75.41580264569181 (Old Acc): 91.0 (New Acc): 64.3888888888889 

2025-01-11 04:53:47,409 [trainer.py] => All params: 173669121
2025-01-11 04:53:47,410 [trainer.py] => Trainable params: 2071809
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 872.30 M params.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 16, 16) = 1024 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/ldm/text2img-large/model.ckpt with 0 missing and 2 unexpected keys
Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
Setting learning rate to 2.00e-02 =  4 (batchsize) * 5.00e-03 (base_lr)
2025-01-11 04:54:06,685 [asp.py] => Learning on 95-100
2025-01-11 04:54:06,710 [asp.py] => training set size: 25, fc construct set size: 25


Class Inversion:   0%|          | 0/10 [00:00<?, ?it/s][A[AClass Inversion:   0%|          | 0/10 [33:35<?, ?it/s]
Class Inversion:   0%|          | 0/10 [16:51<?, ?it/s]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s]Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:35<02:23, 35.83s/it]Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:12<01:48, 36.25s/it]Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:49<01:13, 36.59s/it]Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:26<00:36, 36.86s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:04<00:00, 37.06s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:04<00:00, 36.81s/it]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s]Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.68s/it]Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:15<01:52, 37.60s/it]Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:15, 37.55s/it]Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:30<00:37, 37.51s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.47s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.51s/it]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s]Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.52s/it]Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.42s/it]Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.40s/it]Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.40s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.38s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:06<00:00, 37.40s/it]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s]Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:29, 37.49s/it]Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.45s/it]Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.45s/it]Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.47s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.46s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.46s/it]
Sampling:   0%|          | 0/5 [00:00<?, ?it/s]Sampling:  20%|â–ˆâ–ˆ        | 1/5 [00:37<02:30, 37.62s/it]Sampling:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:14<01:52, 37.47s/it]Sampling:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:14, 37.44s/it]Sampling:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:29<00:37, 37.40s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.37s/it]Sampling: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:07<00:00, 37.41s/it]
2025-01-11 05:09:48,086 [asp.py] => total parameters: 173672961
2025-01-11 05:09:48,086 [asp.py] => trainable parameters: 2075649
backbone.TIP 27648
backbone.Prompt_Encoder.fc_mu.0.weight 393216
backbone.Prompt_Encoder.fc_mu.0.bias 256
backbone.Prompt_Encoder.fc_mu.1.weight 589824
backbone.Prompt_Encoder.fc_mu.1.bias 2304
backbone.Prompt_Encoder.fc_std.0.weight 393216
backbone.Prompt_Encoder.fc_std.0.bias 256
backbone.Prompt_Encoder.fc_std.1.weight 589824
backbone.Prompt_Encoder.fc_std.1.bias 2304
fc.weight 76800
fc.sigma 1
2025-01-11 05:10:35,157 [trainer.py] => Top1 curve: [97.8, 95.8, 86.47, 84.0, 83.04, 79.1, 76.03, 73.4, 73.04, 71.3, 71.71, 69.72, 68.49, 67.84, 65.64, 66.35, 66.48, 66.61, 65.79, 64.44]
2025-01-11 05:10:35,158 [trainer.py] => Average Accuracy (Top1): 74.65249999999999   (Harmonic Accuracy): 74.48394150608172 (Old Acc): 91.0 (New Acc): 63.04210526315789 

2025-01-11 05:10:35,158 [trainer.py] => 

Class Inversion:   0%|          | 0/10 [16:28<?, ?it/s]
